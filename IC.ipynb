{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadEpisodes(fichier):\n",
    "    \"\"\" Loads episodes in arrays \"\"\"\n",
    "    \n",
    "    # Load the file\n",
    "    with open(fichier, 'r') as f:\n",
    "        episodes = []\n",
    "        for episode in f.readlines():                                           # Read lines one by one\n",
    "            episode = np.array([p.split(':')                                    # Remove the last ';' and split':'\n",
    "                                for p in episode[:-2].split(';')], float)\n",
    "            episode = np.array(episode, int)\n",
    "            episode = episode[episode[:,1].argsort()]                           # Sort the array in order of the \n",
    "            episodes.append(episode)                                            # infection time \n",
    "        \n",
    "    return episodes       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IC():\n",
    "    def __init__(self, episodes, nbIteration=1):\n",
    "        \"\"\" Algorithme IC (Independent Cascade)\n",
    "            Setting up the inference mechanism and the learning algorithm of\n",
    "            infections probabilities.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.episodes = episodes                                                # Array of episodes\n",
    "        self.nbIteration = nbIteration                                          # Nb Iterations for reaching convergence\n",
    "        self.nbUser = max([max(epi[:,0]) for epi in self.episodes]) + 1         # Nomber of users or distincts nodes\n",
    "        self.predecessors = defaultdict(dict)                                   # Dictionary of predecessors for each user\n",
    "        self.successors = defaultdict(dict)                                     # Dictionary of successors for each user\n",
    "        self.dMoins = np.zeros((self.nbUser, self.nbUser))                      # Set of episodes D-\n",
    "        self.dPlus = {(i,j):[] for i in range(0,self.nbUser)                    # Set of episodes D+\n",
    "                      for j in range(0, self.nbUser)}   \n",
    "        self.theta = np.array([[ np.random.random()                             # Probability of the precedent step ô\n",
    "                                for i in range(0, self.nbUser)]             \n",
    "                               for j in range(0, self.nbUser)])\n",
    "        \n",
    "    \n",
    "    def createGraph(self):\n",
    "        \"\"\" Creates the graph (tree) of episodes\"\"\"\n",
    "        \n",
    "        for episode in self.episodes:\n",
    "            listeSuccessors = [episode[episode[:,1] > episode[i,1]][:,0]        # List of list of successors for each user\n",
    "                                for i in range(len(episode))]   \n",
    "            for i, successeur in enumerate(listeSuccessors):                    # for the list of successors of each user\n",
    "                for v in successeur:                                            # for every successor of a user\n",
    "                    u, proba = episode[i,0], np.random.random()                 # Generate a probability so within (0,1)\n",
    "                    self.successors[u][v] = proba                               # u ---(proba)---> v \n",
    "                    self.predecessors[v][u] = proba                             # v ---(proba)---> u\n",
    "\n",
    "        \n",
    "    def ptD(self):\n",
    "        \"\"\" Estimates each success probability \"\"\"\n",
    "        \n",
    "        p = dict()\n",
    "        for d, episode in enumerate(self.episodes):\n",
    "            users, tempsU = episode[:,0], np.unique(episode[:,1])               # List of users of an episode and distinct\n",
    "            p[d] = np.ones(self.nbUser)                                         # time\n",
    "            for t in range(1, len(tempsU)):                                           # For each time tU of the episode D\n",
    "                ptd, hasPred = 1., False\n",
    "                for u, user in enumerate(users):\n",
    "                    predU = episode[episode[:,1] < tempsU[t]][:,0]              # List of predecessors of user u at time tU\n",
    "                    for v in predU:\n",
    "                        if v in self.predecessors[user]:\n",
    "                            ptd *= (1 - self.theta[v][user])\n",
    "                            hasPred = True\n",
    "                    if hasPred:\n",
    "                        p[d][u] = 1-ptd\n",
    "        return p\n",
    "                    \n",
    "        \n",
    "    \n",
    "    def setOfdPlus(self):\n",
    "        \"\"\" This method fills the set of episodes D+ which satisfies\n",
    "            both u € D(t) and v € D(>t) \"\"\"\n",
    "        \n",
    "        for d, episode in enumerate(self.episodes):\n",
    "            for i in range(0,len(episode)):\n",
    "                for j in range(0,len(episode)):\n",
    "                    u, v = episode[i][0], episode[j][0]\n",
    "                    tu, tv = episode[i][1], episode[j][1]\n",
    "                    if u != v and tv > tu:                                      # If it's not the same user and v is infected\n",
    "                        self.dPlus[u,v].append(d)                               # after u, then add the episode to the set\n",
    "                        \n",
    "    \n",
    "    def setOfdMoins(self):\n",
    "        \"\"\" This method fills the set of episodes D- which satisfies\n",
    "            both u € D(t) and v not € D(t) \"\"\"\n",
    "        \n",
    "        for episode in self.episodes:\n",
    "            for i in range(0,len(episode)):\n",
    "                for j in range(0, self.nbUser):\n",
    "                    if (j not in episode[:,0]):\n",
    "                        self.dMoins[episode[i][0]][j] += 1\n",
    "                        \n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\" Estimates each diffusion probability \"\"\"\n",
    "        \n",
    "        self.createGraph()\n",
    "        self.setOfdPlus()\n",
    "        self.setOfdMoins()\n",
    "        \n",
    "        for i in range(0, self.nbIteration):\n",
    "            p = self.ptD()\n",
    "            for u in range(0, self.nbUser):\n",
    "                for v in range(0, self.nbUser):\n",
    "                    sumThetaPtd = 0\n",
    "                    sumDSets = len(self.dPlus[u,v]) + self.dMoins[u][v]\n",
    "                    for d in self.dPlus[u,v]:\n",
    "                        sumThetaPtd += self.theta[u][v]/p[d][v]\n",
    "                    self.theta[u][v] = sumThetaPtd/sumDSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05523535         nan  0.05408906  0.11084702  0.05900183  0.10486607\n",
      "  0.05594093  0.00786007  0.01328483  0.0850231   0.0637469   0.10498114\n",
      "  0.0773769   0.01342088  0.12632155  0.10783061  0.0514721   0.0334151\n",
      "  0.08704321  0.05405921  0.00058558  0.00151584  0.17896522  0.06578457\n",
      "  0.00920494  0.09418698  0.08699895  0.09485255  0.01397375  0.04040093\n",
      "  0.06736768  0.08598154  0.00071239  0.04268263  0.06241718  0.04652047\n",
      "  0.06027433  0.15081401  0.01824538  0.00485031  0.10264537  0.06836479\n",
      "  0.16671521  0.01736387  0.01958326  0.00024252  0.03706491  0.01988232\n",
      "  0.1177455   0.08615251  0.03210392  0.07246299  0.04998572  0.10789648\n",
      "  0.02613847  0.01781894  0.03147888  0.0673931   0.08840583  0.05539892\n",
      "  0.00246661  0.12333019  0.09969643  0.08902023  0.08723418  0.08798865\n",
      "  0.1989361   0.1118617   0.11391862  0.10339978  0.11310786  0.12097764\n",
      "  0.11898297  0.07896499  0.05966964  0.04297484  0.12932045  0.1251069\n",
      "  0.0634086   0.11636987  0.10845749  0.10058585  0.07620402  0.02755385\n",
      "  0.07637896  0.0191279   0.010944    0.05432986  0.03728615  0.01837286\n",
      "  0.08237565  0.11048784  0.03512063  0.07597644  0.09343423  0.01335651\n",
      "  0.05191548  0.08262586  0.03748365  0.0046897 ]\n"
     ]
    }
   ],
   "source": [
    "ic = IC(loadEpisodes(\"cascades_train.txt\"))\n",
    "ic.fit()\n",
    "print(ic.theta[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
